{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 딥러닝 성능 올리기 \n-학습을 더 많이 \n-layer을 더 쌓기\n-이미지 손실 줄이기,이미지 사이즈 적당히 줄여주기,이미지 사이즈를 늘려주는게 점수 개선이된다. "},{"metadata":{},"cell_type":"markdown","source":"zip파일이고, csv 아님 "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"그림 하나 하나 열어보기 "},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open('train/cat.1.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"사진이 있고 모델을 통해 학습한다~ \n머신러닝할때 1. 데이터전처리 (데이터 프레임을 만들어서 칼럼 2개 -> 만드고임/ 하나는 주소 하나는 정답값) 2."},{"metadata":{"trusted":true},"cell_type":"code","source":"#데이터 접근##\nimport glob \nglob.glob('train/*') #.jpg는 안적어도 됨\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.DataFrame({'path':glob.glob('train/*')})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* apply(): 딥러닝 머신러닝에 자주 사용. 괄호 안에서 함수 만들기 "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['path'].apply(lambda x:x.split('/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['path'].apply(lambda x:x.split('/')[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['path'].apply(lambda x:x.split('/')[1].split('.')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target']=train['path'].apply(lambda x:x.split('/')[1].split('.')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"학습을 할 수 있도록 전처리를 간단하게,라이브러리 가져와서 작업 "},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.DataFrame({'path':glob.glob('test/*')})\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIDG=ImageDataGenerator(horizontal_flip=True) \n#이미지 칼럼을 맞춰준다. 우리 데이터의 차원이 항상 똑같아야 한다. 이미지에서는 사이즈가 다르기 때문에 통일해주고자 한다.\n#이미지 용량 때문에 batch 조절 해주면서 진행해야 한다. 다른 변환 없이 자동으로 내부적으로 이미지 처리 해주고 얘를 통과해서 트레인 셋에서 학습할거임\n#augmentation 을 통해 데이터 증식 시키기,좌우반전 이런거 체크 -> 줌인 줌앗,노이즈, 위아래반전 등이 있다. \n#트레인과 테스트 패턴을 체크하고 나서 추가쓰,augumentation넣을거면 epoch도 늘려주기 -> 원본 데이터 모두 학습시키기 위해서 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator=IDG.flow_from_dataframe(train, x_col='path',y_col='target',target_size=(300,300),batch_size=32) #dataset 이름,x_column, y_column, batch_size=100장씩 \ntest_generator=IDG.flow_from_dataframe(test,x_col='path',y_col=None,target_size=(300,300),batch_size=32,class_mode=None,shuffle=False)#class_mode=none 기본값이 categorical,testset에는 정답값이 없으니까  test셋에는 꼭 필요함,shuffle은 안하면 제출시 원하는 데이터의 아이디에 맞게 정답값이 섞이게 됨 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델링 / 이미지 학습 중 "},{"metadata":{},"cell_type":"markdown","source":"1.Inception v3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras import Sequential #층을 쌓는다는 느낌으로 \n#from keras.applications.inception_v3 import InceptionV3 #최대한 최신 모델 가져오기\n#from keras.layers import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model=Sequential()\n#model.add(InceptionV3(weights='imagenet',include_top=False,pooling='avg')) \n\n#model.add(Dense(2,activation='softmax'))\n\n#model.compile(optimizer='adam', metrics=['acc'], loss='categorical_crossentropy')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. 일반 이미지 모델 "},{"metadata":{"trusted":true},"cell_type":"code","source":"#모델 층 쌓기 \n#model =Sequential() \n\n#model.add(Conv2D(32,(3,3),activation='relu',input_shape=(100,100,3))) \n#model.add(Flatten())\n#model.add(Dense(2,activation='softmax')) \n#model.summary()\n#model.compile(optimizer='adam', metrics=['acc'], loss='categorical_crossentropy') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#모델 층 쌓기 \nmodel =Sequential() #모델 선언 시작할게, 이제 입력층이 나올거다 \n\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(100,100,3))) #입력층으로 들어갈 때 cnn층이 필요하다.convolution layer인데 2차원, 보통은 2의 제곱이 들어간다. 얼마나 많은 특징을 추출하는지가 효율적인거\n#알아서 32개의 특징을 추출한다. #(3,3)이미지 처리에 있어서 고정,가장 효율적임 #비선형성을 학습할 수 있어야한다. #주로 relu를 많이 쓴다. #input_size제시해주고 채널까지-> 안맞춰주면 오류가 생긴다. \n#Flatten : 매개변수 층이 필요함, 층이 안맞아서 연결해주는 역할 \nmodel.add(Flatten())#Denselayer1차원이니까 펴주는 역할 \nmodel.add(Dense(2,activation='softmax')) \n#최소한 층이 2개가 있어야 한다. 입력층-출력층 출력층은 거의 항상 Denselayer(), \n#맨 마지막 출력층인 경우에만 softmax. 밖으로 나갈 때 확률값으로 출력해야함\n#새로운 데이터가 들어왔을 때는 어떤 class인지 알 수 있어야 한다.정답 클래스의 개수(고양이의 확률 or 개의 확률 )가 필요하다. 이건 이진 분류니까 2 \n#출력물 지날 때 활성화 함수-> 확률로 바뀌어야함\n#sigmoid/ softmax 모두 가능/ 멀티 클래스일때 softmax가 편하다. 출력층이 softmax일때 모델링이 잘 됨!\nmodel.summary()\nmodel.compile(optimizer='adam', metrics=['acc'], loss='categorical_crossentropy') # 모델을 컴파일 시켜준다. 학습을 해나가면서 최적화하기위함/ 손실=>cross이거 고정 특히 다중 multiclass에서 고정임, 행렬, 최적화 metrics->평가 방식,정확도의 직관성에 관해서 \n#y=wx+b(y=정답값,x=input값, 정답을 잘 맞출 수 있게 하는 W를 찾아나가는게 핵심,처음에는 아무값으로 설정되다가 학습을 통해서 업데이트 된다.w=로스 및 손실함수를 통해 가중치를 점점 조절해나간다.),optimizer=gradient_descent"},{"metadata":{},"cell_type":"markdown","source":"#가중치=random으로 시작했는데 Imagenet에서 들고옴.이미 여기에서 모델을 돌린상태의 가중치를 들고 와서 우리 모델에 사용하겠다. \n#고양이나 강아지 자체가 imagenet에서 이미 클래스들로 들어와있음 \n#기본적으로 사진's 공통점, 픽셀값으로 들어가있다, 직선정보나 곡선,명암등에 있어서 기본적으로 존재함. \n#배경정보가 클래스 정보에 영향을 미치는데 이미 물체 이런거에 관한 가중치계산이 끝났음, 배경정보를 무시할 수 있다. 이를 전이학습이라 하는거여\n#include_top:딥러닝 구조 상으로 입력층이 아래인데, 이는 출력층을 포함하지 않겠다는 뜻. 출력층을 직접 만들어주기 위해서 안 포함. \n#Flatten->1차원으로 펼쳐주는 역할, 정보가 소실되기도 함, 그래서 pooling avg통해 지엽적인 정보를 덜 날리게\n\nmodel.add(Dense(2,activation='softmax'))\n#고양이 강아지만 나눌려고\nmodel.compile(optimizer='adam', metrics=['acc'], loss='categorical_crossentropy')\n#출력층 제외하고 InceptionV3로 바로 진행하겠다. 요 안에 conv maxpooling 다 들어가있음~\n\n"},{"metadata":{},"cell_type":"markdown","source":"Convolution layer : Conv2D(필터로 특징 추출해주는것, CNN에서는 특징을 뽑아 이미지 처리하기 때문에 )\ntf.keras.layers.Conv2D(\n    filters,\n    kernel_size,\n    strides=(1, 1),\n    padding=\"valid\",\n    data_format=None,\n    dilation_rate=(1, 1),\n    groups=1,\n    activation=None,\n    use_bias=True,\n    kernel_initializer=\"glorot_uniform\",\n    bias_initializer=\"zeros\",\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    **kwargs\n)\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 28, 28, 2)"},{"metadata":{},"cell_type":"markdown","source":"efficinet B1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U git+https://github.com/qubvel/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet.tfkeras import EfficientNetB1\nfrom keras import Sequential\nfrom keras.layers import * \nfrom keras.optimizers import SGD\nmodel=Sequential()\nmodel.add(EfficientNetB1(weights='imagenet',pooling='avg',include_top=False))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer=SGD(lr=0.01,nesterov=True,momentum=0.9),metrics=['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"earlystopping -> overfitting이 또 생길 수 있음\nmodelcheckpoint: 다시 예측하기 전에\nReduceLR-> learning rate 조절, learning rate가 너무 크면, global_min(x=0인지점)으로 못가고 주변을 맴돌게 됨 learning rate가 너무커서 최적이 안되는거임\n이번엔 optimizer바꾸기 adam도 좋은데, SGD 파라미터 조절 필수임 1. learning rate/2.nestrov,방향 자체를 고려해서 다음 방향 설정해야하는데 너무 급변하는데 학습하변 값이 튈 수 있으니까 예전의 방향 고려해서 벡터 설정 /3.momentum 예전 관성을 얼마나 유지할거냐"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\nes=EarlyStopping(patience=5)\nmc=ModelCheckpoint('best.h5',save_best_only=True)\nRL=ReduceLROnPlateau(patience=3,factor=0.2) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RL이 더 커버리면,early stopping되기도 전에 멈춰버리니까, factor은 몇 정도 줄어들꺼냐 "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#모델 학습하기 \nmodel.fit(train_generator,callbacks=[es,mc,RL],epochs=3) #이미 클래스가 분류되어있어서 이미 y값이 정답값도 적용되어있다! ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"batch=100개씩 들어옴,25000개 중에 100개, 그리고 점점 로스 줄여주고 w 바꿔주는거여"},{"metadata":{"trusted":true},"cell_type":"code","source":"#모델예측하기\nresult=model.predict(test_generator,verbose=1) #괄호에 test할 것들을 넣으면 된다. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('/kaggle/input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"각 class가 무슨 데이터인지 체크해, 항상 클래스 1번을 먼저 제출한다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['label']=result[:,1].clip(0.005,0.995) #:모든데이터 ,1은 몇번째 열, 0.005보다 작은애들은 0.005로 바꾸고 0.995 이상으로 큰 애들은 이 값으로 바꾸어버리겠다","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"제출시 id에 맞게 되어야하는데  match가 안맞음"},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['id']=test['path'].apply(lambda x:x.split('/')[1].split('.jpg')[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"id에 맞는 label을 맞춰주는게 엄청 중요하다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('sub_catanddog.csv',index=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-앙상블 모델: 점수 잘나온 모델에 점수를 준다\n-모델 2개를 branch로 만들어서 컴퓨팅 진행,functional api "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}